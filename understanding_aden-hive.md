# üèóÔ∏è Understanding Aden Hive Framework: A Co-Founder's Deep Dive

> **Author**: Praveen Kumar  
> **Date**: February 9, 2026  
> **Purpose**: Complete architectural understanding of the Aden Hive framework for meaningful contributions

---

## üìå Table of Contents

1. [Executive Summary](#executive-summary)
2. [What Problem Does Hive Solve?](#what-problem-does-hive-solve)
3. [Core Innovation](#core-innovation)
4. [Complete Architecture Breakdown](#complete-architecture-breakdown)
5. [The Five-Layer System](#the-five-layer-system)
6. [Visual Workflow](#visual-workflow)
7. [Key Technical Concepts](#key-technical-concepts)
8. [File Structure & Responsibilities](#file-structure--responsibilities)
9. [How Everything Connects](#how-everything-connects)
10. [Real-World Example](#real-world-example)
11. [What Makes Hive Special](#what-makes-hive-special)

---

## üéØ Executive Summary

**Aden Hive is not just another AI agent framework‚Äîit's a self-improving agent compiler.**

Instead of you writing code to build AI agents, you just tell Hive what you want in plain English, and it:
1. **Generates** the entire agent system automatically
2. **Runs** it with full observability and control
3. **Watches** for failures
4. **Learns** from mistakes
5. **Improves** itself and runs again

Think of it as: **"AI agents that build and fix themselves."**

---

## ü§î What Problem Does Hive Solve?

### Traditional AI Agent Development:
```
Developer writes code ‚Üí Hardcodes workflow ‚Üí Agent runs ‚Üí Breaks
‚Üí Developer debugs ‚Üí Manually fixes code ‚Üí Redeploys ‚Üí Repeat forever
```

**Problems:**
- You need to know exactly how to solve the problem beforehand
- Every workflow is hardcoded (inflexible)
- When things break, you manually fix them
- No learning from failures
- Hard to scale

### Hive's Approach:
```
Developer describes goal in English ‚Üí AI generates agent graph
‚Üí Agent runs ‚Üí If it fails, AI analyzes why ‚Üí AI improves the agent
‚Üí Runs again ‚Üí Eventually succeeds
```

**Benefits:**
- No hardcoding workflows
- Agents adapt to failures automatically
- Self-healing system
- Full observability and control
- Production-ready from day one

---

## üí° Core Innovation

### The Three AI Layers:

1. **Coding Agent (The Builder)** üèóÔ∏è
   - You: "Build an agent that monitors support tickets"
   - Coding Agent: *Generates complete agent system with nodes, connections, tests*

2. **Worker Agent (The Executor)** ‚öôÔ∏è
   - Takes the generated agent and runs it
   - Has access to 102 tools (file ops, web search, APIs, etc.)
   - Can call any LLM (GPT-4, Claude, Gemini, local models)
   - Can pause for human input when needed

3. **Adaptive Loop (The Learner)** üîÑ
   - Watches executions
   - Captures failures with full context
   - Tells Coding Agent what went wrong
   - Coding Agent generates improved version
   - Rinse and repeat

---

## üèõÔ∏è Complete Architecture Breakdown

### The Big Picture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    YOU (Developer)                     ‚îÇ
‚îÇ   "Build an agent to analyze CSV files and send        ‚îÇ
‚îÇ    email summaries to my team every Monday"            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ü§ñ CODING AGENT (The Architect)                ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  Reads your goal ‚Üí Thinks ‚Üí Generates:                ‚îÇ
‚îÇ  ‚Ä¢ Node graph (the agent structure)                   ‚îÇ
‚îÇ  ‚Ä¢ Connection code (how nodes talk)                   ‚îÇ
‚îÇ  ‚Ä¢ Test cases (how to verify it works)                ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  Output: A complete agent exported to exports/        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚öôÔ∏è RUNTIME ENGINE (The Executor)               ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  Loads your agent ‚Üí Runs it node by node              ‚îÇ
‚îÇ  Each node gets:                                       ‚îÇ
‚îÇ  ‚Ä¢ Memory (to remember things)                         ‚îÇ
‚îÇ  ‚Ä¢ Tools (102 MCP tools)                               ‚îÇ
‚îÇ  ‚Ä¢ LLM access (GPT-4, Claude, etc.)                    ‚îÇ
‚îÇ  ‚Ä¢ Monitoring (every action logged)                    ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  Execution flow:                                       ‚îÇ
‚îÇ  Node 1 ‚Üí Edge ‚Üí Node 2 ‚Üí Edge ‚Üí Node 3 ‚Üí ...         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                           ‚îÇ
        ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìä MONITORING   ‚îÇ     ‚îÇ  ‚öñÔ∏è EVALUATION       ‚îÇ
‚îÇ                  ‚îÇ     ‚îÇ                      ‚îÇ
‚îÇ  ‚Ä¢ Live logs     ‚îÇ     ‚îÇ  Did it work?        ‚îÇ
‚îÇ  ‚Ä¢ Cost tracking ‚îÇ     ‚îÇ  ‚Ä¢ YES ‚Üí Success ‚úÖ  ‚îÇ
‚îÇ  ‚Ä¢ TUI dashboard ‚îÇ     ‚îÇ  ‚Ä¢ NO ‚Üí Failure ‚ùå   ‚îÇ
‚îÇ  ‚Ä¢ WebSocket     ‚îÇ     ‚îÇ                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº (if failure)
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  üîÑ ADAPTATION LOOP  ‚îÇ
                         ‚îÇ                      ‚îÇ
                         ‚îÇ  1. Capture why it   ‚îÇ
                         ‚îÇ     failed           ‚îÇ
                         ‚îÇ  2. Analyze root     ‚îÇ
                         ‚îÇ     cause            ‚îÇ
                         ‚îÇ  3. Generate better  ‚îÇ
                         ‚îÇ     agent            ‚îÇ
                         ‚îÇ  4. Run again        ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üé≠ The Five-Layer System

### Layer 1: Coding Agent (Builder)
**Location**: `core/framework/builder/`, `core/framework/mcp/`

**What it does**: Converts your English goal into a working agent

**Process**:
```
1. Parse Goal
   Input: "Monitor support tickets and escalate urgent ones"
   Output: Structured goal with success criteria

2. Generate Nodes
   Creates: 
   - llm_generate (for text generation)
   - llm_tool_use (for calling tools)
   - router (for conditional branching)
   - function (for custom Python code)
   - HITL (for human input)
   - conversation (for multi-turn interactions)

3. Create Connections
   Generates Python code that connects nodes:
   "If ticket is urgent, route to escalation_node
    else route to normal_processing_node"

4. Generate Tests
   Creates constraint tests and success tests

5. Export
   Saves everything to exports/your_agent/
```

**Key Files**:
- `builder/workflow.py` - Main workflow generation logic
- `builder/query.py` - Analyzes past runs for improvements
- `graph/goal.py` - Goal definition and parsing
- `graph/node.py` - Base node implementation (75KB!)
- `graph/edge.py` - Connection code generation

---

### Layer 2: Runtime Execution Engine
**Location**: `core/framework/runtime/`, `core/framework/graph/`

**What it does**: Runs your agent with full SDK support

**The SDK Wrapper Magic**:
Every node automatically gets:
```python
node = {
    "shared_memory": {},      # Share data between nodes
    "llm_provider": LiteLLM,  # Call any LLM
    "tools": [102 MCP tools], # File ops, web, APIs
    "monitoring": Logger,     # Track everything
    "local_memory": RLM,      # Retrieval-augmented memory
}
```

**Execution Flow**:
```
1. Load agent from exports/
2. Initialize runtime context
3. For each node:
   a. Wrap with SDK
   b. Execute node logic
   c. If needs LLM ‚Üí Call LiteLLM (supports 100+ models)
   d. If needs tools ‚Üí Call MCP tools
   e. If needs human ‚Üí Pause and wait (HITL)
   f. Log everything
   g. Evaluate edge condition
   h. Move to next node
4. End when reaching terminal node
```

**Key Files**:
- `runtime/agent_runtime.py` - Main runtime interface
- `runtime/shared_state.py` - Cross-node memory
- `runtime/event_bus.py` - Event-driven messaging
- `graph/executor.py` - Graph execution engine (74KB!)
- `graph/worker_node.py` - Worker agent implementation
- `graph/event_loop_node.py` - Event-driven execution

---

### Layer 3: Control Plane & Observability
**Location**: `core/framework/runtime/`, `core/framework/tui/`

**What it does**: Gives you full visibility and control

**Features**:
1. **Real-time Monitoring**
   - WebSocket streaming of all events
   - See every node execution live
   - Watch LLM calls in real-time

2. **TUI Dashboard** (`hive tui`)
   - Interactive terminal interface
   - Live graph visualization
   - Event log viewer
   - Chat with agent

3. **Budget Control**
   - Set spending limits per agent
   - Track LLM costs in real-time
   - Automatic model degradation (GPT-4 ‚Üí GPT-3.5 if budget low)
   - Throttling to prevent runaway costs

4. **Runtime Logging**
   - SQLite database with all execution data
   - Searchable logs
   - Failure analysis

**Key Files**:
- `runtime/execution_stream.py` - WebSocket streaming
- `runtime/runtime_logger.py` - Logging system
- `runtime/outcome_aggregator.py` - Result collection
- `tui/` - Terminal dashboard

---

### Layer 4: Outcome Evaluation (The Judge)
**Location**: `core/framework/graph/judge.py`

**What it does**: Decides if the agent succeeded or failed

**Process**:
```
1. Get agent output
2. Compare against success criteria from goal
3. Validate constraints
4. Calculate metrics
5. Decision:
   - SUCCESS ‚Üí Return result to user ‚úÖ
   - FAILURE ‚Üí Trigger adaptation loop ‚ùå
```

**Example**:
```python
Goal: "Send email summary"
Success Criteria:
- Email must be sent
- Must contain data summary
- Must be under 500 words

Judge evaluates:
‚úÖ Email sent: True
‚úÖ Has summary: True
‚ùå Word count: 623 (too long)

Result: FAILURE ‚Üí Capture why and trigger adaptation
```

---

### Layer 5: Adaptation Loop (Self-Improvement)
**Location**: `core/framework/builder/query.py`, `core/framework/runtime/outcome_aggregator.py`

**What it does**: Makes the agent better after failures

**The Self-Improvement Cycle**:
```
1. CAPTURE FAILURE
   Runtime Logger saves:
   - Full execution trace
   - Every node output
   - All LLM calls
   - Tool results
   - Error messages
   - Decision points

2. ANALYZE
   BuilderQuery asks:
   - What was the agent trying to do?
   - What went wrong?
   - Where did it fail?
   - Are there patterns across multiple failures?

3. EVOLVE
   Coding Agent generates improvements:
   - "The email was too long because we didn't set
      a max_words parameter in the summarization node.
      Adding max_words=450 to ensure under 500."

4. REDEPLOY
   New version exported to exports/your_agent_v2/

5. RETRY
   Run the improved agent

6. LOOP
   If still fails, repeat
   If succeeds, done! ‚úÖ
```

**This is the killer feature** - agents that actually learn and improve themselves.

---

## üîÑ Visual Workflow

### Happy Path (Everything Works)
```
üë§ User
  ‚îÇ
  ‚îÇ "Build a CSV analyzer agent"
  ‚îÇ
  ‚ñº
ü§ñ Coding Agent
  ‚îÇ
  ‚îÇ Generates agent graph with nodes:
  ‚îÇ [Read CSV] ‚Üí [Analyze] ‚Üí [Generate Report] ‚Üí [Send Email]
  ‚îÇ
  ‚ñº
üíæ exports/csv_analyzer/
  ‚îÇ
  ‚îÇ Agent saved
  ‚îÇ
  ‚ñº
‚öôÔ∏è Runtime: hive run exports/csv_analyzer
  ‚îÇ
  ‚îÇ Node 1: Read CSV ‚úÖ
  ‚îÇ Node 2: Analyze data ‚úÖ
  ‚îÇ Node 3: Generate report ‚úÖ
  ‚îÇ Node 4: Send email ‚úÖ
  ‚îÇ
  ‚ñº
‚öñÔ∏è Judge: Evaluate
  ‚îÇ
  ‚îÇ SUCCESS! All criteria met ‚úÖ
  ‚îÇ
  ‚ñº
üìß Result delivered to user
```

### Failure & Adaptation Path
```
üë§ User
  ‚îÇ
  ‚îÇ "Build a web scraper agent"
  ‚îÇ
  ‚ñº
ü§ñ Coding Agent
  ‚îÇ
  ‚îÇ Generates: [Scrape] ‚Üí [Parse] ‚Üí [Save]
  ‚îÇ
  ‚ñº
‚öôÔ∏è Runtime: First attempt
  ‚îÇ
  ‚îÇ Node 1: Scrape ‚ùå FAILED (website blocked)
  ‚îÇ
  ‚ñº
‚öñÔ∏è Judge: FAILURE ‚ùå
  ‚îÇ
  ‚ñº
üîÑ Adaptation Loop
  ‚îÇ
  ‚îÇ 1. Capture: Website returned 403 Forbidden
  ‚îÇ 2. Analyze: No user agent in request
  ‚îÇ 3. Evolve: Add user agent header to scraper
  ‚îÇ 4. Redeploy: v2 with user agent
  ‚îÇ
  ‚ñº
‚öôÔ∏è Runtime: Second attempt
  ‚îÇ
  ‚îÇ Node 1: Scrape ‚úÖ (now works!)
  ‚îÇ Node 2: Parse ‚úÖ
  ‚îÇ Node 3: Save ‚úÖ
  ‚îÇ
  ‚ñº
‚öñÔ∏è Judge: SUCCESS ‚úÖ
  ‚îÇ
  ‚ñº
üì¶ Result delivered
```

---

## üß† Key Technical Concepts

### 1. Nodes (The Building Blocks)

Think of nodes as **Lego blocks** for AI agents. Each node does one thing:

**Node Types**:
```python
llm_generate
# Generates text using LLM
# Example: "Write a summary of this data"

llm_tool_use
# Uses LLM to decide which tool to call and calls it
# Example: LLM decides to search web, then calls web_search tool

router
# Makes decisions and routes to different nodes
# Example: "If urgent, go to node A, else go to node B"

function
# Runs custom Python code
# Example: Calculate average from numbers

HITL (Human-in-the-Loop)
# Pauses and asks human for input
# Example: "Should I send this email? (yes/no)"

conversation
# Multi-turn dialogue
# Example: Chat with user to gather requirements

event_loop_node
# Reacts to events
# Example: Watch for new files in folder
```

**Key Insight**: You don't create nodes manually. The Coding Agent creates them based on your goal.

---

### 2. Edges (The Connections)

**Traditional frameworks**: Edges are hardcoded arrows
```python
node_a.connect_to(node_b)  # Static, inflexible
```

**Hive**: Edges are generated Python code
```python
# Generated edge code:
def edge_a_to_b(node_a_output):
    if node_a_output.get('urgent') == True:
        return 'escalation_node'
    elif node_a_output.get('category') == 'sales':
        return 'sales_node'
    else:
        return 'general_node'
```

**Why this matters**: The Coding Agent can generate complex routing logic without you writing any code.

---

### 3. SDK Wrapper (The Magic Layer)

**Problem**: Every node needs access to memory, tools, LLMs, etc.

**Solution**: SDK Wrapper automatically injects everything:

```python
# You define a simple node:
def my_node(input_data):
    return {"result": "hello"}

# SDK wraps it:
class WrappedNode:
    def __init__(self, original_node):
        self.node = original_node
        self.memory = SharedMemory()      # Injected
        self.tools = MCPToolkit()         # Injected
        self.llm = LiteLLM()              # Injected
        self.logger = RuntimeLogger()     # Injected
    
    def execute(self, input_data):
        # Before execution: setup
        self.logger.log('Starting node')
        
        # Execute
        result = self.node(input_data)
        
        # After execution: cleanup
        self.logger.log('Node complete')
        return result
```

**Result**: Every node is "supercharged" automatically.

---

### 4. MCP Tools (The Toolbox)

**MCP** = Model Context Protocol (standard for AI tool integration)

Hive includes **102 pre-built tools**:

```
üìÅ File Operations
   - read_file, write_file, list_directory
   - csv_read, csv_write
   - pdf_extract_text

üåê Web & APIs
   - web_search (Google, Bing)
   - web_scrape (BeautifulSoup)
   - api_call (generic HTTP)

üíº Business Integrations
   - github_* (create issue, PR, etc.)
   - slack_send_message
   - email_send
   - hubspot_* (CRM operations)
   - apollo_* (sales intelligence)

üß† Memory & Data
   - memory_store (short-term)
   - memory_retrieve (long-term)
   - database_query
```

**Usage**: Nodes can call any tool. The SDK handles authentication via credential store.

---

### 5. LiteLLM Integration

**Problem**: Different LLM providers have different APIs

**Solution**: LiteLLM provides unified interface

```python
# Same code works for all providers:
response = llm.generate(
    model="gpt-4",           # or "claude-3-5-sonnet"
    messages=[...],          # or "gemini-pro"
    temperature=0.7          # or "ollama/llama3"
)                            # or any of 100+ models
```

**Supported Providers**:
- OpenAI (GPT-4, GPT-4o, GPT-3.5)
- Anthropic (Claude 3.5 Sonnet, Opus, Haiku)
- Google (Gemini Pro, Ultra)
- Local (Ollama, LMStudio)
- Open source (DeepSeek, Mistral, Llama)
- 100+ more...

---

### 6. Human-in-the-Loop (HITL)

**Concept**: Sometimes agents need human judgment

**How it works**:
```python
# HITL node in agent:
{
    "type": "HITL",
    "question": "Should I send this email to all customers?",
    "timeout": 300,  # 5 minutes
    "default": "no",  # If timeout, default answer
    "escalate_to": "supervisor@company.com"
}
```

**Process**:
1. Agent reaches HITL node
2. Execution pauses
3. Shows question in TUI dashboard
4. Waits for human response
5. If timeout: uses default or escalates
6. Continues execution with answer

**Use cases**:
- Approving financial transactions
- Reviewing generated content before publishing
- Handling edge cases agent isn't sure about

---

### 7. Credential Store

**Location**: `~/.hive/credentials`

**Purpose**: Securely store API keys, tokens, passwords

**Features**:
- Encrypted storage
- Per-tool credentials
- OAuth token management
- Integration with enterprise secret managers (future)

**Setup**:
```bash
./quickstart.sh
# Wizard asks for:
# - OpenAI API key
# - Anthropic API key
# - GitHub token
# - etc.
```

**Usage**: Tools automatically fetch credentials when needed.

---

### 8. Runtime Logging

**Everything is logged** to SQLite database:

```sql
Tables:
- runs (each agent execution)
- decisions (every node choice)
- outcomes (results of decisions)
- events (all system events)
- costs (LLM API costs)
```

**Benefits**:
- Full execution replay
- Failure analysis
- Cost tracking
- Performance optimization
- Adaptation learning

---

## üìÇ File Structure & Responsibilities

### Core Framework (`core/framework/`)

```
core/framework/
‚îÇ
‚îú‚îÄ‚îÄ builder/                    # Goal ‚Üí Agent generation
‚îÇ   ‚îú‚îÄ‚îÄ workflow.py            # Main agent generation logic
‚îÇ   ‚îî‚îÄ‚îÄ query.py               # Analyze runs, suggest improvements
‚îÇ
‚îú‚îÄ‚îÄ graph/                      # Node graph system
‚îÇ   ‚îú‚îÄ‚îÄ node.py                # Base node (75KB - most important!)
‚îÇ   ‚îú‚îÄ‚îÄ edge.py                # Dynamic connection code
‚îÇ   ‚îú‚îÄ‚îÄ executor.py            # Graph execution engine (74KB)
‚îÇ   ‚îú‚îÄ‚îÄ flexible_executor.py   # Alternative executor
‚îÇ   ‚îú‚îÄ‚îÄ worker_node.py         # Worker agent type
‚îÇ   ‚îú‚îÄ‚îÄ event_loop_node.py     # Event-driven node
‚îÇ   ‚îú‚îÄ‚îÄ conversation.py        # Conversational node
‚îÇ   ‚îú‚îÄ‚îÄ hitl.py                # Human-in-the-loop
‚îÇ   ‚îú‚îÄ‚îÄ goal.py                # Goal definition
‚îÇ   ‚îú‚îÄ‚îÄ judge.py               # Outcome evaluation
‚îÇ   ‚îú‚îÄ‚îÄ validator.py           # Graph validation
‚îÇ   ‚îú‚îÄ‚îÄ safe_eval.py           # Safe code execution
‚îÇ   ‚îî‚îÄ‚îÄ code_sandbox.py        # Sandboxed execution
‚îÇ
‚îú‚îÄ‚îÄ runtime/                    # Execution runtime
‚îÇ   ‚îú‚îÄ‚îÄ agent_runtime.py       # Main runtime interface
‚îÇ   ‚îú‚îÄ‚îÄ stream_runtime.py      # Streaming execution
‚îÇ   ‚îú‚îÄ‚îÄ shared_state.py        # Cross-node memory
‚îÇ   ‚îú‚îÄ‚îÄ event_bus.py           # Event system
‚îÇ   ‚îú‚îÄ‚îÄ execution_stream.py    # WebSocket streaming
‚îÇ   ‚îú‚îÄ‚îÄ outcome_aggregator.py  # Result collection
‚îÇ   ‚îú‚îÄ‚îÄ runtime_logger.py      # Logging
‚îÇ   ‚îî‚îÄ‚îÄ runtime_log_store.py   # SQLite storage
‚îÇ
‚îú‚îÄ‚îÄ llm/                        # LLM provider integration
‚îÇ   ‚îî‚îÄ‚îÄ [LiteLLM integration code]
‚îÇ
‚îú‚îÄ‚îÄ mcp/                        # Model Context Protocol
‚îÇ   ‚îî‚îÄ‚îÄ agent_builder_server.py # MCP server for Claude/Cursor
‚îÇ
‚îú‚îÄ‚îÄ credentials/                # Credential management
‚îÇ   ‚îî‚îÄ‚îÄ [Encrypted key storage]
‚îÇ
‚îú‚îÄ‚îÄ storage/                    # Persistent storage
‚îÇ   ‚îî‚îÄ‚îÄ [Checkpoints, sessions]
‚îÇ
‚îú‚îÄ‚îÄ tui/                        # Terminal UI
‚îÇ   ‚îî‚îÄ‚îÄ [Dashboard implementation]
‚îÇ
‚îú‚îÄ‚îÄ schemas/                    # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ [Data validation schemas]
‚îÇ
‚îî‚îÄ‚îÄ cli.py                      # Command-line interface
```

### Tools (`tools/src/aden_tools/tools/`)

```
tools/src/aden_tools/tools/
‚îÇ
‚îú‚îÄ‚îÄ file_system_toolkits/      # File operations
‚îú‚îÄ‚îÄ csv_tool/                  # CSV processing
‚îú‚îÄ‚îÄ pdf_read_tool/             # PDF extraction
‚îú‚îÄ‚îÄ web_search_tool/           # Web search
‚îú‚îÄ‚îÄ web_scrape_tool/           # Web scraping
‚îú‚îÄ‚îÄ github_tool/               # GitHub integration
‚îú‚îÄ‚îÄ slack_tool/                # Slack messaging
‚îú‚îÄ‚îÄ email_tool/                # Email sending
‚îú‚îÄ‚îÄ apollo_tool/               # Apollo.io sales
‚îú‚îÄ‚îÄ hubspot_tool/              # HubSpot CRM
‚îî‚îÄ‚îÄ runtime_logs_tool/         # Log analysis
```

---

## üîó How Everything Connects

### Data Flow Diagram

```
1. GOAL INPUT
   Natural language ‚Üí Coding Agent
   
2. GRAPH GENERATION
   Coding Agent ‚Üí Generates nodes + edges ‚Üí Validates
   
3. EXPORT
   Agent graph ‚Üí Saved to exports/your_agent/
   
4. LOADING
   hive run ‚Üí Loads graph ‚Üí Initializes runtime
   
5. EXECUTION
   Runtime ‚Üí Wraps nodes with SDK ‚Üí Executes sequentially
   
6. NODE EXECUTION
   Node ‚Üí Needs LLM? ‚Üí Calls LiteLLM ‚Üí Gets response
   Node ‚Üí Needs tool? ‚Üí Calls MCP tool ‚Üí Gets result
   Node ‚Üí Needs human? ‚Üí Shows HITL prompt ‚Üí Waits
   
7. LOGGING
   Every action ‚Üí Runtime Logger ‚Üí SQLite database
   
8. EVALUATION
   Final output ‚Üí Judge ‚Üí Compare to success criteria
   
9. DECISION
   Success? ‚Üí Return result to user
   Failure? ‚Üí Capture data ‚Üí Trigger adaptation
   
10. ADAPTATION (if failed)
    Failure data ‚Üí BuilderQuery ‚Üí Analyzes
    BuilderQuery ‚Üí Suggests improvements ‚Üí Coding Agent
    Coding Agent ‚Üí Generates v2 ‚Üí Back to step 3
```

---

## üé¨ Real-World Example

Let's walk through a **complete example** to see everything in action.

### Scenario: "Build an agent that finds trending GitHub repos and posts them to Slack"

#### Step 1: Goal Definition
```
You: "I want an agent that finds trending Python repos on GitHub 
      and posts a summary to our #tech-news Slack channel daily."
```

#### Step 2: Coding Agent Generates

**Goal Object**:
```python
goal = {
    "description": "Find trending Python repos and post to Slack",
    "success_criteria": [
        "Must search GitHub trending",
        "Must filter for Python language",
        "Must get top 5 repos",
        "Must format as summary",
        "Must post to #tech-news",
        "Summary under 500 words"
    ],
    "schedule": "daily"
}
```

**Generated Nodes**:
```python
Node 1: github_trending_search
  Type: llm_tool_use
  Tools: [github_search, web_scrape]
  Prompt: "Search for trending Python repositories on GitHub today"

Node 2: filter_top_repos
  Type: function
  Code: 
    def filter(repos):
        return repos[:5]  # Top 5

Node 3: generate_summary
  Type: llm_generate
  Prompt: "Create an engaging summary of these repos in under 500 words"

Node 4: review_summary
  Type: HITL
  Question: "Review this summary before posting. Approve? (yes/no)"
  Timeout: 300  # 5 minutes
  Default: "yes"

Node 5: post_to_slack
  Type: llm_tool_use
  Tools: [slack_post]
  Prompt: "Post this summary to #tech-news channel"
```

**Generated Edges**:
```python
Edge 1‚Üí2:
  if len(node1_output.repos) == 0:
      return 'error_handler'
  else:
      return 'filter_top_repos'

Edge 2‚Üí3:
  return 'generate_summary'

Edge 3‚Üí4:
  if len(node3_output.summary) > 500:
      return 'generate_summary'  # Retry
  else:
      return 'review_summary'

Edge 4‚Üí5:
  if node4_output.approved:
      return 'post_to_slack'
  else:
      return 'end'  # Don't post
```

**Exported to**: `exports/github_slack_agent/`

#### Step 3: First Run

```bash
$ hive run exports/github_slack_agent

[11:00:00] Starting run...
[11:00:01] Node 1: github_trending_search
           ‚Üí Calling web_scrape tool
           ‚Üí Found 50 repos
           ‚úÖ Success
           
[11:00:05] Node 2: filter_top_repos
           ‚Üí Filtering to top 5
           ‚úÖ Success
           
[11:00:06] Node 3: generate_summary
           ‚Üí Calling LLM (gpt-4)
           ‚Üí Generated 750 words
           ‚ùå Too long! (>500 words)
           
[11:00:08] Edge 3‚Üí3: Retry generate_summary
           
[11:00:09] Node 3: generate_summary (retry)
           ‚Üí Calling LLM with max_words=450
           ‚Üí Generated 420 words
           ‚úÖ Success
           
[11:00:10] Node 4: review_summary (HITL)
           ‚Üí Pausing for human review
           ‚Üí Showing in TUI: "Approve? (yes/no)"
           
[You in TUI]: yes
           
[11:02:15] Node 4: review_summary
           ‚Üí Received approval
           ‚úÖ Success
           
[11:02:16] Node 5: post_to_slack
           ‚Üí Calling slack_post tool
           ‚ùå FAILED: Missing Slack token
           
[11:02:17] Judge: FAILURE
           ‚Üí Reason: Slack authentication failed
           ‚Üí Triggering adaptation...
```

#### Step 4: Adaptation Loop

```
BuilderQuery Analysis:
  "The agent failed because the Slack tool couldn't authenticate.
   Looking at the credential store, no SLACK_TOKEN was found.
   The user needs to add their Slack token to the credential store."

Coding Agent Evolution:
  "I'll add a pre-check node before post_to_slack that verifies
   the Slack token exists. If not, I'll add an HITL node that
   asks the user to provide it."

Generated v2:
  Added Node 4.5: verify_slack_credentials
    Type: function
    Code:
      def verify():
          token = credentials.get('SLACK_TOKEN')
          if not token:
              return {'has_token': False}
          return {'has_token': True}
  
  Added Node 4.6: request_slack_token (HITL)
    Question: "Please provide your Slack API token"
    Stores: credentials.set('SLACK_TOKEN', user_input)
```

#### Step 5: Second Run (v2)

```bash
$ hive run exports/github_slack_agent

[11:05:00] Starting run (v2)...
[11:05:01] Nodes 1-4: ‚úÖ All success
[11:05:10] Node 4.5: verify_slack_credentials
           ‚Üí Checking for SLACK_TOKEN
           ‚Üí Not found
           ‚úÖ Detected missing credential
           
[11:05:11] Node 4.6: request_slack_token (HITL)
           ‚Üí Asking user for token
           
[You in TUI]: xoxb-your-token-here
           
[11:06:30] Node 4.6: request_slack_token
           ‚Üí Saved to credential store
           ‚úÖ Success
           
[11:06:31] Node 5: post_to_slack
           ‚Üí Calling slack_post tool
           ‚Üí Posted to #tech-news
           ‚úÖ SUCCESS!
           
[11:06:32] Judge: SUCCESS
           ‚Üí All criteria met ‚úÖ
           ‚Üí Delivered result
```

#### Result:
**Your Slack channel now has**:
```
üî• Trending Python Repos Today

1. **awesome-ml** (‚≠ê 2.5k today)
   A curated list of machine learning resources
   
2. **fast-api-starter** (‚≠ê 1.8k today)
   Production-ready FastAPI template
   
...
```

---

## ‚≠ê What Makes Hive Special

### 1. No Hardcoding
**Traditional**:
```python
# You write this:
def agent():
    repos = github.search('trending')
    filtered = repos[:5]
    summary = llm.generate(f"Summarize {filtered}")
    slack.post(summary)
```

**Hive**:
```python
# You write this:
"Find trending repos and post to Slack"

# Hive generates everything
```

---

### 2. Self-Healing
**Traditional**:
```
Agent breaks ‚Üí You debug ‚Üí You fix code ‚Üí Redeploy
(Manual, time-consuming, requires expert)
```

**Hive**:
```
Agent breaks ‚Üí Hive debugs ‚Üí Hive fixes ‚Üí Rerun
(Automatic, fast, no expert needed)
```

---

### 3. Full Observability
**Traditional**: Add logging manually, set up monitoring, build dashboards

**Hive**: Everything logged automatically:
- Every node execution
- Every LLM call (with tokens and cost)
- Every tool call
- Every decision point
- Real-time TUI dashboard
- WebSocket streaming

---

### 4. Production Ready
**Traditional frameworks**: Great for demos, hard to productionize

**Hive features for production**:
- ‚úÖ Budget controls (never overspend on LLM calls)
- ‚úÖ Cost tracking (know exactly what everything costs)
- ‚úÖ HITL for critical decisions
- ‚úÖ Resumable sessions (checkpoint and resume)
- ‚úÖ Error recovery
- ‚úÖ Multi-agent coordination
- ‚úÖ Real-time monitoring
- ‚úÖ Self-hosting (no vendor lock-in)

---

### 5. Model Agnostic
Works with **any LLM**:
- Hosted: OpenAI, Anthropic, Google, Cohere
- Open source: Llama, Mistral, DeepSeek
- Local: Ollama, LMStudio
- Custom: Your own models

**Same code, different models** - just change the model name.

---

### 6. Tool Ecosystem
**102 pre-built MCP tools** covering:
- Files & data
- Web & APIs  
- Communication
- Business systems
- Databases
- And more...

**Plus**: Easy to add your own tools following MCP standard.

---

## üéì Key Takeaways

### For Developers:
1. **Stop hardcoding workflows** - Describe goals instead
2. **Stop manual debugging** - Let the adaptation loop handle it
3. **Stop worrying about LLM providers** - LiteLLM handles all of them
4. **Stop building monitoring** - It's built-in
5. **Stop fearing production** - It's production-ready from day one

### For Understanding:
1. **Coding Agent** = Builds agents from goals
2. **Worker Agent** = Executes agents with SDK support
3. **Adaptation Loop** = Improves agents from failures
4. **SDK Wrapper** = Magic layer that supercharges nodes
5. **MCP Tools** = Toolbox of 102 capabilities

### For Architecture:
1. **5 Layers**: Builder ‚Üí Runtime ‚Üí Control ‚Üí Judge ‚Üí Adaptation
2. **Everything flows through** the Runtime with SDK wrapper
3. **All data logged** to SQLite for analysis
4. **Failures trigger** automatic improvement cycle
5. **Humans can intervene** via HITL nodes

---

## üöÄ Next Steps

Now that I have this deep understanding, I'm ready to:

1. **Find meaningful issues** in the codebase
2. **Propose valuable improvements**
3. **Submit high-quality PRs**
4. **Build example agents** to showcase capabilities
5. **Extend the tool ecosystem**
6. **Contribute to documentation**
7. **Help other developers** understand the framework

---

## üìö References

- **Main Repo**: https://github.com/adenhq/hive
- **Documentation**: https://docs.adenhq.com/
- **Discord**: https://discord.com/invite/MXE49hrKDk
- **Company**: https://adenhq.com (Y Combinator backed)
- **License**: Apache 2.0 (fully open source)

---

## üí≠ Final Thoughts

**Hive is not just a framework - it's a paradigm shift.**

From: "I need to code this agent"
To: "I need to describe what I want"

From: "My agent broke, I need to fix it"
To: "My agent broke, it's fixing itself"

From: "How do I monitor this?"
To: "Everything is already monitored"

From: "This is too expensive"
To: "Budget controls prevent overspending"

From: "I don't know which LLM to use"
To: "Use any LLM, switch anytime"

**The future of AI agents is self-improving, goal-driven, and production-ready. That future is Hive.**

---

*Document created as part of my journey to contribute meaningfully to the Aden Hive project.*

*Ready to make impactful contributions! üöÄ*